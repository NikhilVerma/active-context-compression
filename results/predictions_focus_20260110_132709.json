[
  {
    "instance_id": "mwaskom__seaborn-2848",
    "model_name_or_path": "claude-haiku-4-5-20251001_focus",
    "model_patch": "diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py\nindex 2469df00..90f4b78c 100644\n--- a/seaborn/_core/plot.py\n+++ b/seaborn/_core/plot.py\n@@ -1162,7 +1162,7 @@ class Plotter:\n         for view in subplots:\n             view_df = self._filter_subplot_data(df, view)\n             axes_df = view_df[coord_cols]\n-            with pd.option_context(\"mode.use_inf_as_null\", True):\n+            with pd.option_context(\"mode.use_inf_as_na\", True):\n                 axes_df = axes_df.dropna()\n             for var, values in axes_df.items():\n                 scale = view[f\"{var[0]}scale\"]\n@@ -1288,7 +1288,7 @@ class Plotter:\n \n                 axes_df = self._filter_subplot_data(df, view)\n \n-                with pd.option_context(\"mode.use_inf_as_null\", True):\n+                with pd.option_context(\"mode.use_inf_as_na\", True):\n                     if keep_na:\n                         # The simpler thing to do would be x.dropna().reindex(x.index).\n                         # But that doesn't work with the way that the subset iteration\ndiff --git a/seaborn/_oldcore.py b/seaborn/_oldcore.py\nindex c9218c1f..fd57efdf 100644\n--- a/seaborn/_oldcore.py\n+++ b/seaborn/_oldcore.py\n@@ -1093,7 +1093,7 @@ class VectorPlotter:\n                 parts = []\n                 grouped = self.plot_data[var].groupby(self.converters[var], sort=False)\n                 for converter, orig in grouped:\n-                    with pd.option_context('mode.use_inf_as_null', True):\n+                    with pd.option_context('mode.use_inf_as_na', True):\n                         orig = orig.dropna()\n                         if var in self.var_levels:\n                             # TODO this should happen in some centralized location\ndiff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\nindex 8526f44b..6bee2f2a 100644\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -1558,6 +1558,12 @@ class PairGrid(Grid):\n         if self._dropna:\n             data = data.dropna()\n \n+        # Filter data to only include hue values that are in hue_order\n+        if self._hue_var is not None and self._hue_order is not None:\n+            # Create a mask for rows where hue value is in hue_order\n+            hue_mask = data[self._hue_var].isin(self._hue_order)\n+            data = data[hue_mask]\n+\n         x = data[x_var]\n         y = data[y_var]\n         if self._hue_var is None:\ndiff --git a/seaborn/categorical.py b/seaborn/categorical.py\nindex 7df91b05..01087311 100644\n--- a/seaborn/categorical.py\n+++ b/seaborn/categorical.py\n@@ -1842,7 +1842,7 @@ class _LVPlotter(_CategoricalPlotter):\n         vals = np.asarray(vals)\n         # Remove infinite values while handling a 'object' dtype\n         # that can come from pd.Float64Dtype() input\n-        with pd.option_context('mode.use_inf_as_null', True):\n+        with pd.option_context('mode.use_inf_as_na', True):\n             vals = vals[~pd.isnull(vals)]\n         n = len(vals)\n         p = self.outlier_prop\ndiff --git a/seaborn/cm.py b/seaborn/cm.py\nindex 4e39fe7a..a57e9731 100644\n--- a/seaborn/cm.py\n+++ b/seaborn/cm.py\n@@ -1571,6 +1571,8 @@ _lut_dict = dict(\n \n )\n \n+from matplotlib import colormaps\n+\n for _name, _lut in _lut_dict.items():\n \n     _cmap = colors.ListedColormap(_lut, _name) \n@@ -1579,7 +1581,7 @@ for _name, _lut in _lut_dict.items():\n     _cmap_r = colors.ListedColormap(_lut[::-1], _name + \"_r\")  \n     locals()[_name + \"_r\"] = _cmap_r\n \n-    mpl_cm.register_cmap(_name, _cmap)\n-    mpl_cm.register_cmap(_name + \"_r\", _cmap_r)\n+    colormaps.register(_cmap)\n+    colormaps.register(_cmap_r)\n \n del colors, mpl_cm\n\\ No newline at end of file\n"
  },
  {
    "instance_id": "pallets__flask-4045",
    "model_name_or_path": "claude-haiku-4-5-20251001_focus",
    "model_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\nindex 5fb84d86..85d8225e 100644\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -188,6 +188,7 @@ class Blueprint(Scaffold):\n             template_folder=template_folder,\n             root_path=root_path,\n         )\n+        assert \".\" not in name, \"Blueprint names should not contain dots\"\n         self.name = name\n         self.url_prefix = url_prefix\n         self.subdomain = subdomain\n"
  },
  {
    "instance_id": "psf__requests-2148",
    "model_name_or_path": "claude-haiku-4-5-20251001_focus",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 0dc55568..98639e1e 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -9,6 +9,7 @@ This module contains the primary objects that power Requests.\n \n import collections\n import datetime\n+import socket\n \n from io import BytesIO, UnsupportedOperation\n from .hooks import default_hooks\n@@ -22,7 +23,7 @@ from .packages.urllib3.util import parse_url\n from .packages.urllib3.exceptions import DecodeError\n from .exceptions import (\n     HTTPError, RequestException, MissingSchema, InvalidURL,\n-    ChunkedEncodingError, ContentDecodingError)\n+    ChunkedEncodingError, ContentDecodingError, ConnectionError)\n from .utils import (\n     guess_filename, get_auth_from_url, requote_uri,\n     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n@@ -640,10 +641,15 @@ class Response(object):\n                     raise ChunkedEncodingError(e)\n                 except DecodeError as e:\n                     raise ContentDecodingError(e)\n+                except socket.error as e:\n+                    raise ConnectionError(e)\n             except AttributeError:\n                 # Standard file-like object.\n                 while True:\n-                    chunk = self.raw.read(chunk_size)\n+                    try:\n+                        chunk = self.raw.read(chunk_size)\n+                    except socket.error as e:\n+                        raise ConnectionError(e)\n                     if not chunk:\n                         break\n                     yield chunk\n"
  },
  {
    "instance_id": "pylint-dev__pylint-5859",
    "model_name_or_path": "claude-haiku-4-5-20251001_focus",
    "model_patch": "diff --git a/pylint/checkers/misc.py b/pylint/checkers/misc.py\nindex 69149e61a..28978365f 100644\n--- a/pylint/checkers/misc.py\n+++ b/pylint/checkers/misc.py\n@@ -121,9 +121,9 @@ class EncodingChecker(BaseChecker):\n \n         notes = \"|\".join(re.escape(note) for note in self.config.notes)\n         if self.config.notes_rgx:\n-            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\\b\"\n+            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})(?=\\W|$)\"\n         else:\n-            regex_string = rf\"#\\s*({notes})\\b\"\n+            regex_string = rf\"#\\s*({notes})(?=\\W|$)\"\n \n         self._fixme_pattern = re.compile(regex_string, re.I)\n \n"
  },
  {
    "instance_id": "scikit-learn__scikit-learn-10297",
    "model_name_or_path": "claude-haiku-4-5-20251001_focus",
    "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3b..6469cdbcfc 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1301,6 +1301,12 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n         weights inversely proportional to class frequencies in the input data\n         as ``n_samples / (n_classes * np.bincount(y))``\n \n+    store_cv_values : boolean, default=False\n+        Flag indicating if the cross-validation values corresponding to\n+        each alpha should be stored in the `cv_values_` attribute (see\n+        below). This flag is only compatible with `cv=None` (i.e. using\n+        Generalized Cross-Validation).\n+\n     Attributes\n     ----------\n     cv_values_ : array, shape = [n_samples, n_alphas] or \\\n@@ -1333,10 +1339,11 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n         self.class_weight = class_weight\n \n     def fit(self, X, y, sample_weight=None):\ndiff --git a/sklearn/linear_model/tests/test_ridge.py b/sklearn/linear_model/tests/test_ridge.py\nindex ee44da5d56..9124dec067 100644\n--- a/sklearn/linear_model/tests/test_ridge.py\n+++ b/sklearn/linear_model/tests/test_ridge.py\n@@ -598,6 +598,24 @@ def test_ridgecv_store_cv_values():\n     assert_equal(r.cv_values_.shape, (n_samples, n_responses, n_alphas))\n \n \n+\n+\n+def test_ridgeclassifiercv_store_cv_values():\n+    # Test RidgeClassifierCV's store_cv_values attribute.\n+    rng = np.random.RandomState(42)\n+\n+    n_samples = 8\n+    n_features = 5\n+    x = rng.randn(n_samples, n_features)\n+    y = np.array([0, 0, 1, 1, 0, 1, 1, 0])\n+    alphas = [1e-1, 1e0, 1e1]\n+    n_alphas = len(alphas)\n+\n+    r = RidgeClassifierCV(alphas=alphas, store_cv_values=True)\n+    r.fit(x, y)\n+    assert_equal(r.cv_values_.shape, (n_samples, n_alphas))\n+\n+\n def test_ridgecv_sample_weight():\n     rng = np.random.RandomState(0)\n     alphas = (0.1, 1.0, 10.0)\n"
  }
]